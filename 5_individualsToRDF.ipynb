{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import rdfpandas as rpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import TOPO1K as GeoDataFrame and prepare column names for RDFs \n",
    "\n",
    "ibb = gpd.GeoDataFrame.from_file('data/clean_ibb.geojson')\n",
    "\n",
    "ibb['uri'] = 'http://ulusalharita.tr/id/topo#' + ibb['fid']\n",
    "ibb['uri_geo'] = 'http://ulusalharita.tr/go/topo#' + ibb['fid']\n",
    "\n",
    "ibb_geo = ibb[['uri_geo','geometry']].copy()\n",
    "ibb_geo = ibb_geo.to_crs(epsg=4326)\n",
    "\n",
    "ibb['uri_geo'] = '__' + ibb['uri_geo'] + '__'\n",
    "\n",
    "ibb['rdfType'] = \"owl:NamedIndividual\"\n",
    "ibb['class'] = \"spo:BuildingAndFacilities\"\n",
    "\n",
    "ibb_geo['hasScale'] = \"spo:largeScale\"\n",
    "ibb_geo['rdfType'] = \"owl:NamedIndividual\"\n",
    "ibb_geo['class'] = \"sf:Polygon\"\n",
    "\n",
    "ibb.drop(columns=['fid','geometry'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a list of URIs from column names for the creation of datatype properties\n",
    "\n",
    "ibb_col = ibb.columns.tolist()\n",
    "ls_ibb = ['http://ulusalharita.tr/ont/spo#' + 'has' + i[0].upper() + i[1:] for i in ibb_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dict for column rename\n",
    "\n",
    "ibb_dict = dict(zip(ibb_col, ls_ibb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://ulusalharita.tr/ont/spo#hasClass'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove unnecessary URIs from dict\n",
    "\n",
    "ibb_dict.pop('uri')\n",
    "ibb_dict.pop('uri_geo')\n",
    "ibb_dict.pop('rdfType')\n",
    "ibb_dict.pop('class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename column names according to the created dict\n",
    "\n",
    "ibb.rename(columns=ibb_dict,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename remainder column names\n",
    "\n",
    "ibb.rename(columns={'uri_geo':'http://www.opengis.net/ont/geosparql#hasGeometry',\n",
    "                    'rdfType':'http://www.w3.org/1999/02/22-rdf-syntax-ns#type',\n",
    "                    'class':'http://www.w3.org/1999/02/22-rdf-syntax-ns#type'},\n",
    "                    inplace=True)\n",
    "ibb_geo.rename(columns={'geometry':'http://www.opengis.net/ont/geosparql#asWKT',\n",
    "                        'rdfType':'http://www.w3.org/1999/02/22-rdf-syntax-ns#type',\n",
    "                        'hasScale':'http://ulusalharita.tr/ont/spo#hasScale',\n",
    "                        'class':'http://www.w3.org/1999/02/22-rdf-syntax-ns#type'},\n",
    "                        inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set index as feature URIs\n",
    "\n",
    "ibb.set_index('uri',inplace=True)\n",
    "ibb_geo.set_index('uri_geo',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import OSM as GeoDataFrame and prepare column names for RDFs \n",
    "\n",
    "osm = gpd.GeoDataFrame.from_file('data/clean_osm.geojson')\n",
    "\n",
    "osm['uri'] = 'http://ulusalharita.tr/id/topo#' + osm['fid']\n",
    "osm['uri_geo'] = 'http://ulusalharita.tr/go/topo#' + osm['fid']\n",
    "\n",
    "osm_geo = osm[['uri_geo','geometry']].copy()\n",
    "osm_geo = osm_geo.to_crs(epsg=4326)\n",
    "\n",
    "osm['uri_geo'] = '__' + osm['uri_geo'] + '__'\n",
    "\n",
    "osm['rdfType'] = \"owl:NamedIndividual\"\n",
    "osm['class'] = \"spo:Social_Culture\"\n",
    "\n",
    "osm_geo['hasScale'] = \"spo:mediumScale\"\n",
    "osm_geo['rdfType'] = \"owl:NamedIndividual\"\n",
    "osm_geo['class'] = \"sf:Polygon\"\n",
    "\n",
    "osm.drop(columns=['fid','geometry'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a list of URIs from column names for the creation of datatype properties\n",
    "\n",
    "osm_col = osm.columns.tolist()\n",
    "ls_osm = ['http://ulusalharita.tr/ont/spo#' + 'has' + i[0].upper() + i[1:] for i in osm_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dict for column rename\n",
    "\n",
    "osm_dict = dict(zip(osm_col, ls_osm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://ulusalharita.tr/ont/spo#hasClass'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove unnecessary URIs from dict\n",
    "\n",
    "osm_dict.pop('uri')\n",
    "osm_dict.pop('uri_geo')\n",
    "osm_dict.pop('rdfType')\n",
    "osm_dict.pop('class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename column names according to the created dict\n",
    "\n",
    "osm.rename(columns=osm_dict,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename remainder column names\n",
    "\n",
    "osm.rename(columns={'uri_geo':'http://www.opengis.net/ont/geosparql#hasGeometry',\n",
    "                    'rdfType':'http://www.w3.org/1999/02/22-rdf-syntax-ns#type',\n",
    "                    'class':'http://www.w3.org/1999/02/22-rdf-syntax-ns#type'},\n",
    "                    inplace=True)\n",
    "\n",
    "osm_geo.rename(columns={'geometry':'http://www.opengis.net/ont/geosparql#asWKT',\n",
    "                        'rdfType':'http://www.w3.org/1999/02/22-rdf-syntax-ns#type',\n",
    "                        'hasScale':'http://ulusalharita.tr/ont/spo#hasScale',\n",
    "                        'class':'http://www.w3.org/1999/02/22-rdf-syntax-ns#type'},\n",
    "                        inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename remainder column names\n",
    "\n",
    "osm['http://ulusalharita.tr/ont/spo#hasTimestamp'] = osm['http://ulusalharita.tr/ont/spo#hasTimestamp'] + 'datatype2date'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set index as feature URIs\n",
    "\n",
    "osm.set_index('uri',inplace=True)\n",
    "osm_geo.set_index('uri_geo',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import TOPO25K as GeoDataFrame and prepare column names for RDFs \n",
    "\n",
    "hgm = gpd.GeoDataFrame.from_file('data/clean_hgm.geojson')\n",
    "\n",
    "hgm['uri'] = 'http://ulusalharita.tr/id/topo#' + hgm['fid']\n",
    "hgm['uri_geo'] = 'http://ulusalharita.tr/go/topo#' + hgm['fid']\n",
    "\n",
    "hgm_geo = hgm[['uri_geo','geometry']].copy()\n",
    "hgm_geo = hgm_geo.to_crs(epsg=4326)\n",
    "\n",
    "hgm['uri_geo'] = '__' + hgm['uri_geo'] + '__'\n",
    "\n",
    "hgm['rdfType'] = \"owl:NamedIndividual\"\n",
    "hgm['class'] = \"spo:Settlement\"\n",
    "\n",
    "hgm_geo['hasScale'] = \"spo:smallScale\"\n",
    "hgm_geo['rdfType'] = \"owl:NamedIndividual\"\n",
    "hgm_geo['class'] = \"sf:Polygon\"\n",
    "\n",
    "hgm.drop(columns=['fid','geometry','shape_leng','shape_area'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a list of URIs from column names for the creation of datatype properties\n",
    "\n",
    "hgm_col = hgm.columns.tolist()\n",
    "ls_hgm = ['http://ulusalharita.tr/ont/spo#' + 'has' + i[0].upper() + i[1:] for i in hgm_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dict for column rename\n",
    "\n",
    "hgm_dict = dict(zip(hgm_col, ls_hgm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://ulusalharita.tr/ont/spo#hasClass'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove unnecessary URIs from dict\n",
    "\n",
    "hgm_dict.pop('uri')\n",
    "hgm_dict.pop('uri_geo')\n",
    "hgm_dict.pop('rdfType')\n",
    "hgm_dict.pop('class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename column names according to the created dict\n",
    "\n",
    "hgm.rename(columns=hgm_dict,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename remainder column names\n",
    "\n",
    "hgm.rename(columns={'uri_geo':'http://www.opengis.net/ont/geosparql#hasGeometry',\n",
    "                    'rdfType':'http://www.w3.org/1999/02/22-rdf-syntax-ns#type',\n",
    "                    'class':'http://www.w3.org/1999/02/22-rdf-syntax-ns#type'},\n",
    "                    inplace=True)\n",
    "\n",
    "hgm_geo.rename(columns={'geometry':'http://www.opengis.net/ont/geosparql#asWKT',\n",
    "                        'rdfType':'http://www.w3.org/1999/02/22-rdf-syntax-ns#type',\n",
    "                        'hasScale':'http://ulusalharita.tr/ont/spo#hasScale',\n",
    "                        'class':'http://www.w3.org/1999/02/22-rdf-syntax-ns#type'},\n",
    "                        inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set index as feature URIs\n",
    "\n",
    "hgm.set_index('uri',inplace=True)\n",
    "hgm_geo.set_index('uri_geo',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correct data types of newly created dataframes\n",
    "\n",
    "ibb = ibb.apply(pd.to_numeric, errors='ignore')\n",
    "ibb_geo = ibb_geo.apply(pd.to_numeric, errors='ignore')\n",
    "osm = osm.apply(pd.to_numeric, errors='ignore')\n",
    "osm_geo = osm_geo.apply(pd.to_numeric, errors='ignore')\n",
    "hgm = hgm.apply(pd.to_numeric, errors='ignore')\n",
    "hgm_geo = hgm_geo.apply(pd.to_numeric, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace all null values to 'None'\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "ibb     = ibb.replace({np.NaN: None})\n",
    "ibb_geo = ibb_geo.replace({np.NaN: None})\n",
    "osm     = osm.replace({np.NaN: None})\n",
    "osm_geo = osm_geo.replace({np.NaN: None})\n",
    "hgm     = hgm.replace({np.NaN: None})\n",
    "hgm_geo = hgm_geo.replace({np.NaN: None})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all created dataframes to RDF Graph\n",
    "\n",
    "graph = rpd.to_graph(ibb) + rpd.to_graph(ibb_geo) + rpd.to_graph(osm) +\n",
    "        rpd.to_graph(osm_geo) + rpd.to_graph(hgm) + rpd.to_graph(hgm_geo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add necessary prefixes\n",
    "\n",
    "graph.bind('geo', 'http://www.opengis.net/ont/geosparql#')\n",
    "graph.bind('spo', 'http://ulusalharita.tr/ont/spo#')\n",
    "graph.bind('idt', 'http://ulusalharita.tr/id/topo#')\n",
    "graph.bind('got', 'http://ulusalharita.tr/go/topo#')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all triples that has None value as predicate\n",
    "\n",
    "from rdflib import Literal\n",
    "\n",
    "graph.remove((None, None, Literal(\"None\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Serialize graph as Turtle format\n",
    "\n",
    "graph.serialize('data/individuals.ttl',format='turtle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open created Turtle file and make last modifications for a consistent file and write all data to a file as individuals\n",
    "\n",
    "with open('data/individuals.ttl','r') as ind:\n",
    "    inddata = ind.read()\n",
    "    inddata = inddata.replace('\"owl:NamedIndividual\"','owl:NamedIndividual')\n",
    "    inddata = inddata.replace('\"spo:smallScale\"','spo:smallScale')\n",
    "    inddata = inddata.replace('\"spo:mediumScale\"','spo:mediumScale')\n",
    "    inddata = inddata.replace('\"spo:largeScale\"','spo:largeScale')\n",
    "    inddata = inddata.replace('\"sf:Polygon\"','sf:Polygon')\n",
    "    inddata = inddata.replace('\"spo:Social_Culture\"','spo:Social_Culture')\n",
    "    inddata = inddata.replace('\"spo:Settlement\"','spo:Settlement')\n",
    "    inddata = inddata.replace('\"spo:BuildingAndFacilities\"','spo:BuildingAndFacilities')\n",
    "    inddata = inddata.replace('))\" ','))\"^^geo:wktLiteral ')\n",
    "    inddata = inddata.replace('datatype2date\"','\"^^xsd:date')\n",
    "    inddata = inddata.replace('\"__','<')\n",
    "    inddata = inddata.replace('__\"','>')\n",
    "    \n",
    "with open('data/individuals.ttl','w') as file:\n",
    "    file.write(inddata)\n",
    "    \n",
    "with open('data/individuals.ttl','r') as fin:\n",
    "    data = fin.read().splitlines(True)\n",
    "    \n",
    "with open('data/individuals.ttl','w') as fout:\n",
    "    fout.writelines(data[5:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:myenv]",
   "language": "python",
   "name": "conda-env-myenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
